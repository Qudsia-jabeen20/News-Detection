{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9uxsu2v0eyzy6eNUP/AnK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qudsia-jabeen20/News-Detection/blob/main/News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai pandas scikit-learn xgboost\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "08Dapa1TdBw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6849dd7"
      },
      "source": [
        "import csv\n",
        "\n",
        "fake_data = []\n",
        "problematic_rows = []\n",
        "\n",
        "with open(\"Fake.csv\", 'r', encoding='utf-8', errors='replace') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    header = next(reader)  # Read the header row\n",
        "    fake_data.append(header) # Add header to the data list\n",
        "    for i, row in enumerate(reader):\n",
        "        try:\n",
        "            # Attempt to process the row - you might need to adjust based on the CSV structure\n",
        "            # For now, just adding the row if it can be read\n",
        "            fake_data.append(row)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {i+2}: {e}\") # +2 for 0-based index and header\n",
        "            problematic_rows.append(i+2) # Store problematic row numbers\n",
        "\n",
        "# Convert the processed data to a DataFrame\n",
        "fake_df_processed = pd.DataFrame(fake_data[1:], columns=fake_data[0])\n",
        "\n",
        "print(f\"Successfully read {len(fake_df_processed)} rows from Fake.csv\")\n",
        "if problematic_rows:\n",
        "    print(f\"Skipped or had issues with rows: {problematic_rows}\")\n",
        "\n",
        "display(fake_df_processed.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66106ba1"
      },
      "source": [
        "import csv\n",
        "\n",
        "real_data = []\n",
        "problematic_rows_real = []\n",
        "\n",
        "with open(\"True.csv\", 'r', encoding='utf-8', errors='replace') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    header_real = next(reader)  # Read the header row\n",
        "    real_data.append(header_real) # Add header to the data list\n",
        "    for i, row in enumerate(reader):\n",
        "        try:\n",
        "            # Attempt to process the row\n",
        "            real_data.append(row)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row {i+2} in True.csv: {e}\") # +2 for 0-based index and header\n",
        "            problematic_rows_real.append(i+2) # Store problematic row numbers\n",
        "\n",
        "# Convert the processed data to a DataFrame\n",
        "real_df_processed = pd.DataFrame(real_data[1:], columns=real_data[0])\n",
        "\n",
        "print(f\"Successfully read {len(real_df_processed)} rows from True.csv\")\n",
        "if problematic_rows_real:\n",
        "    print(f\"Skipped or had issues with rows in True.csv: {problematic_rows_real}\")\n",
        "\n",
        "display(real_df_processed.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7705fe00"
      },
      "source": [
        "# Add labels\n",
        "fake_df_processed[\"label\"] = 0  # Fake\n",
        "real_df_processed[\"label\"] = 1  # Real\n",
        "\n",
        "# Combine and shuffle\n",
        "df = pd.concat([fake_df_processed, real_df_processed], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Keep only useful columns\n",
        "# Assuming 'text' and 'title' are the relevant columns for text data\n",
        "# And 'label' is the newly added label column\n",
        "if 'text' in df.columns and 'title' in df.columns:\n",
        "    df = df[[\"text\", \"title\", \"label\"]]\n",
        "elif 'text' in df.columns:\n",
        "    df = df[[\"text\", \"label\"]]\n",
        "elif 'title' in df.columns:\n",
        "    df = df[[\"title\", \"label\"]]\n",
        "else:\n",
        "    print(\"Warning: Neither 'text' nor 'title' columns found. Keeping all columns and label.\")\n",
        "    df = df.copy()\n",
        "\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train XGBoost\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate\n",
        "preds = model.predict(X_test_vec)\n",
        "print(\"Local Model Accuracy:\", accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "id": "vbSaNXMEhYXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "openai.api_key = userdata.get(\"your API key\")\n",
        "\n",
        "# Initialize the OpenAI client with your API key\n",
        "client = openai.OpenAI(api_key=openai.api_key)\n",
        "\n",
        "def classify_with_openai(news_text):\n",
        "    prompt = f\"\"\"You are a fake news detection expert.\n",
        "Decide if this news is Real or Fake.\n",
        "\n",
        "News: \"{news_text}\"\n",
        "\n",
        "Answer only with \"Fake\" or \"Real\".\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "67wdw1gyhoyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_predict(news_text):\n",
        "    vec = vectorizer.transform([news_text])\n",
        "    local_pred = model.predict(vec)[0]\n",
        "\n",
        "    if local_pred == 1:\n",
        "        local_label = \"Real\"\n",
        "    else:\n",
        "        local_label = \"Fake\"\n",
        "\n",
        "    print(\"Local Model Prediction:\", local_label)\n",
        "\n",
        "    # Optional: verify with OpenAI\n",
        "    gpt_label = classify_with_openai(news_text)\n",
        "    print(\"OpenAI Prediction:\", gpt_label)\n",
        "\n",
        "    if local_label != gpt_label:\n",
        "        print(\"⚠️ Mismatch detected. Needs human review.\")\n",
        "\n",
        "    return local_label, gpt_label\n"
      ],
      "metadata": {
        "id": "_3ikVTvLh8VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Make predictions\n",
        "preds = model.predict(X_test_vec)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, preds))"
      ],
      "metadata": {
        "id": "-LxnvO17ioDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = \"Imran Khan is the President of America\"\n",
        "hybrid_predict(news)\n"
      ],
      "metadata": {
        "id": "8ZuSvEbHiBBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "-kWcssFXjY7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def hybrid_predict_interface(news_text):\n",
        "    # Local model prediction\n",
        "    vec = vectorizer.transform([news_text])\n",
        "    local_pred = model.predict(vec)[0]\n",
        "    local_label = \"Real\" if local_pred == 1 else \"Fake\"\n",
        "\n",
        "    # OpenAI prediction\n",
        "    gpt_label = classify_with_openai(news_text)\n",
        "\n",
        "    # Compare results\n",
        "    warning = \"\"\n",
        "    if local_label != gpt_label:\n",
        "        warning = \"⚠️ Mismatch detected. Needs human review.\"\n",
        "\n",
        "    # Output message\n",
        "    result = f\"\"\"📄 **News:** {news_text}\n",
        "\n",
        "🧠 **Local Model Prediction:** {local_label}\n",
        "🤖 **OpenAI Prediction:** {gpt_label}\n",
        "{warning}\"\"\"\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "HsWSaDm7jbzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=hybrid_predict_interface,\n",
        "    inputs=gr.Textbox(lines=6, placeholder=\"Paste your news article or headline here...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"📰 Fake News Detector (Hybrid: XGBoost + OpenAI)\",\n",
        "    description=\"Enter a news headline or article. The app will check it using a local ML model and OpenAI's GPT. If the two disagree, you'll get a warning for manual review.\",\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "9ftjmhYNjjOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}